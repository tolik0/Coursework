{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../object_detection')\n",
    "from image_detector import crop_minAreaRect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1 = ['Apple Braeburn',\n",
    " 'Apple Golden 1',\n",
    " 'Apple Golden 2',\n",
    " 'Apple Golden 3',\n",
    " 'Apple Granny Smith',\n",
    " 'Apple Red 1',\n",
    " 'Apple Red 2',\n",
    " 'Apple Red 3',\n",
    " 'Apple Red Delicious',\n",
    " 'Apple Red Yellow',\n",
    " 'Apricot',\n",
    " 'Avocado',\n",
    " 'Avocado ripe',\n",
    " 'Banana',\n",
    " 'Banana Red',\n",
    " 'Cactus fruit',\n",
    " 'Carambula',\n",
    " 'Cherry',\n",
    " 'Clementine',\n",
    " 'Cocos',\n",
    " 'Dates',\n",
    " 'Garbage',\n",
    " 'Granadilla',\n",
    " 'Grape Pink',\n",
    " 'Grape White',\n",
    " 'Grape White 2',\n",
    " 'Grapefruit Pink',\n",
    " 'Grapefruit White',\n",
    " 'Guava',\n",
    " 'Huckleberry',\n",
    " 'Kaki',\n",
    " 'Kiwi',\n",
    " 'Kumquats',\n",
    " 'Lemon',\n",
    " 'Lemon Meyer',\n",
    " 'Limes',\n",
    " 'Litchi',\n",
    " 'Mandarine',\n",
    " 'Mango',\n",
    " 'Maracuja',\n",
    " 'Nectarine',\n",
    " 'Orange',\n",
    " 'Papaya',\n",
    " 'Passion Fruit',\n",
    " 'Peach',\n",
    " 'Peach Flat',\n",
    " 'Pear',\n",
    " 'Pear Abate',\n",
    " 'Pear Monster',\n",
    " 'Pear Williams',\n",
    " 'Pepino',\n",
    " 'Pineapple',\n",
    " 'Pitahaya Red',\n",
    " 'Plum',\n",
    " 'Pomegranate',\n",
    " 'Quince',\n",
    " 'Raspberry',\n",
    " 'Salak',\n",
    " 'Strawberry',\n",
    " 'Tamarillo',\n",
    " 'Tangelo']\n",
    "names = ['acerolas',\n",
    " 'apples',\n",
    " 'apricots',\n",
    " 'avocados',\n",
    " 'bananas',\n",
    " 'blackberries',\n",
    " 'blueberries',\n",
    " 'cantaloupes',\n",
    " 'cherries',\n",
    " 'coconuts',\n",
    " 'figs',\n",
    " 'garbage',\n",
    " 'grapefruits',\n",
    " 'grapes',\n",
    " 'guava',\n",
    " 'kiwifruit',\n",
    " 'lemons',\n",
    " 'limes',\n",
    " 'mangos',\n",
    " 'olives',\n",
    " 'oranges',\n",
    " 'passionfruit',\n",
    " 'peaches',\n",
    " 'pears',\n",
    " 'pineapples',\n",
    " 'plums',\n",
    " 'pomegranates',\n",
    " 'raspberries',\n",
    " 'strawberries',\n",
    " 'tomatoes',\n",
    " 'watermelons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "def image_loader(image):\n",
    "    \"\"\"load image, returns cuda tensor\"\"\"\n",
    "    image = loader(image).float()\n",
    "    image = Variable(image, requires_grad=True)\n",
    "    image = image.unsqueeze(0)  #this is for VGG, may not be needed for ResNet\n",
    "    return image.cuda()  #assumes that you're using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"mymodel_finetuning_new_v1.pth\"\n",
    "image_path = \"../test_images/ban_app.jpg\"\n",
    "model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_objects(path):\n",
    "    boundaries = [(np.array([10, 10, 10]), np.array([28, 255, 255])), #yellow\n",
    "                  (np.array([28, 10, 10]), np.array([80, 255, 255])), #green\n",
    "                  (np.array([0, 10, 10]), np.array([10, 255, 255]))] #red\n",
    "\n",
    "\n",
    "    image = cv2.imread(path)\n",
    "    bordersize = 50\n",
    "    image = cv2.copyMakeBorder(image, top=bordersize, bottom=bordersize,\n",
    "                                left=bordersize, right=bordersize,\n",
    "                                borderType=cv2.BORDER_CONSTANT,\n",
    "                                value=[255, 255, 255])\n",
    "    image1 = image.copy()\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    images = []\n",
    "\n",
    "    for (lower, upper) in boundaries:\n",
    "        mask = cv2.inRange(hsv, lower, upper)\n",
    "        res = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "        im2, contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE,\n",
    "                                                    cv2.CHAIN_APPROX_SIMPLE)\n",
    "        index = []\n",
    "\n",
    "        for i in range(len(contours)):\n",
    "            if len(contours[i]) < 50:\n",
    "                index.append(i)\n",
    "\n",
    "        contours = np.delete(contours, index)\n",
    "\n",
    "        for contour in contours:\n",
    "            rect = cv2.minAreaRect(contour)\n",
    "\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int0(box)\n",
    "            startX, startY = min(box, key = lambda x: x[0])[0], min(box, key = lambda x: x[1])[1]\n",
    "            cv2.drawContours(image1, [box], 0, (0, 0, 255), 2)\n",
    "            \n",
    "            # display the prediction\n",
    "            img = crop_minAreaRect(image, rect)\n",
    "            croped_image = image_loader(Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)))\n",
    "            outputs = model(croped_image)[0]\n",
    "            outputs = (outputs.data).cpu().numpy()\n",
    "            print(outputs)\n",
    "            ind = outputs.argsort()[-5:][::-1]\n",
    "            \n",
    "            label = \"\"\n",
    "            for i in ind:\n",
    "                label += \"  {}: {}\".format(names[i], outputs[i]) + \"\\n\"\n",
    "            print(label)\n",
    "        \n",
    "            y, dy = startY, 15\n",
    "            for line in label.split('\\n'):\n",
    "                y += dy\n",
    "                cv2.putText(image1, line, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.3, 1)\n",
    "\n",
    "            img[np.where((img == [0, 0, 0]).all(axis=2))] = [255, 255, 255]\n",
    "            images.append(img)\n",
    "            \n",
    "    cv2.imshow('image', image1)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    return image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.2735041   6.211521   -1.5391865  -1.2306465   0.84314716 -2.2416823\n",
      " -3.2965872  -3.2583218   0.15475285 -1.7169794   0.46864447 -1.4080333\n",
      " -2.4229853  -0.51053745  1.9159007  -1.101838    3.449447    3.0214775\n",
      "  3.9841053   1.5179946   1.0331038  -1.768128   -0.58335435  3.4455507\n",
      "  0.09465442  0.7910308  -0.26092795 -1.8626113  -2.4775634  -0.49538934\n",
      "  1.914089  ]\n",
      "  apples: 6.211521148681641\n",
      "  mangos: 3.984105348587036\n",
      "  lemons: 3.4494469165802\n",
      "  pears: 3.4455506801605225\n",
      "  limes: 3.021477460861206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "images = find_objects(\"../test_images/3.jpg\")\n",
    "\n",
    "# for i in range(len(images)):\n",
    "#     cv2.imshow(f\"{i}\", images[i])\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
